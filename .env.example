# VLM API Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# API Keys (Required for online models)
# =============================================================================

# DashScope API key for Qwen VLM online inference
# Get your key from: https://dashscope.console.aliyun.com/
DASHSCOPE_API_KEY=your_dashscope_api_key_here

# VLM API key for authentication (if require_api_key is enabled)
VLM_API_KEY=your_api_key_here

# =============================================================================
# Server Configuration (Optional - overrides config.yaml)
# =============================================================================

# Server host (default: 0.0.0.0)
# VLM_HOST=0.0.0.0

# Server port (default: 5000)
# VLM_PORT=5000

# Debug mode (default: false)
# VLM_DEBUG=false

# =============================================================================
# Model Configuration (Optional - overrides config.yaml)
# =============================================================================

# Enable/disable local model (default: true)
# VLM_LOCAL_ENABLED=true

# Local model name (default: Qwen/Qwen2-VL-7B-Instruct)
# VLM_LOCAL_MODEL=Qwen/Qwen2-VL-7B-Instruct

# Device for local model: cuda, cpu, or mps (default: cuda)
# VLM_DEVICE=cuda

# Enable/disable online model (default: true)
# VLM_ONLINE_ENABLED=true

# Online model name (default: qwen-vl-plus)
# VLM_ONLINE_MODEL=qwen-vl-plus

# Online API base URL
# VLM_ONLINE_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1

# Request timeout in seconds (default: 30)
# VLM_TIMEOUT=30

# Enable/disable LLM (text-only, fast) (default: true)
# VLM_LLM_ENABLED=true

# LLM model name (default: google/gemma-2-9b)
# VLM_LLM_MODEL=google/gemma-2-9b
# Alternative: meta-llama/Meta-Llama-3.1-8B-Instruct

# Device for LLM: auto, cuda, cpu, or mps (default: auto)
# VLM_LLM_DEVICE=auto

# =============================================================================
# Security Configuration (Optional - overrides config.yaml)
# =============================================================================

# Require API key authentication (default: false)
# VLM_REQUIRE_API_KEY=false

# Enable rate limiting (default: false)
# VLM_RATE_LIMIT=false

# =============================================================================
# Logging Configuration (Optional - overrides config.yaml)
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
# VLM_LOG_LEVEL=INFO
