# VLM API Configuration
# Professional configuration for production deployment

server:
  host: "0.0.0.0"
  port: 5000
  debug: false
  
api:
  name: "VLM Parsing API"
  version: "1.0.0"
  base_path: "/api"
  
models:
  local:
    enabled: false
    model_name: "Qwen/Qwen2-VL-7B-Instruct"
    device: "cuda"  # cuda, cpu, mps
    auto_load: true
    
  online:
    enabled: false
    provider: "dashscope"
    model_name: "qwen-vl-plus"
    base_url: "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
    timeout: 30
    max_retries: 3
  
  llm:
    enabled: false  # Disabled - using Azure OpenAI instead
    model_name: "microsoft/Phi-4-mini-instruct"  # NEW! Phi-4 (3.8B, 128K ctx, Feb 2025)
    # Alternative models:
    # - "google/gemma-2-9b" (WORKING PERFECTLY! 9B params, great with 4bit)
    # - "google/gemma-2-9b-it" (instruction-tuned version)
    # - "meta-llama/Meta-Llama-3.1-8B-Instruct" (8B params)
    # - "microsoft/Phi-3-mini-128k-instruct" (⚠️ cache compatibility issue)
    # - "microsoft/Phi-4-mini-instruct" (3.8B, 200K vocab, best reasoning)
    # - "azure/o1-mini" (Azure OpenAI, requires AZURE_OPENAI_* env vars)
    device: "cuda"  # auto, cuda, cpu, mps
    torch_dtype: "bfloat16"  # bfloat16, float16, float32
    max_new_tokens: 512
    auto_load: true
    quantization: "4bit"  # null, "8bit", "4bit" (requires bitsandbytes)
  
  azure_openai:
    enabled: true  # ✓ ENABLED - Using Azure OpenAI o1-mini
    # Credentials loaded from .env file:
    # - AZURE_OPENAI_ENDPOINT
    # - AZURE_OPENAI_API_KEY
    # - AZURE_OPENAI_API_VERSION
    # - AZURE_OPENAI_DEPLOYMENT_NAME
    deployment_name: "gpt-5-nano"  # Override via AZURE_OPENAI_DEPLOYMENT_NAME
    api_version: "2025-01-01-preview"  # Override via AZURE_OPENAI_API_VERSION
    max_tokens: 4096  # Increased for reasoning models (gpt-5-nano, o1-mini)
    temperature: 0.7
    
prompts:
  system_message: |
    You are a UI automation assistant that generates executable action commands.
    Analyze the UI elements and user task to create a precise action sequence.
    
  action_format: |
    Use these command formats:
    Click(x, y, element_id, "element_description")
    Type(x, y, element_id, "field_name", "text_to_enter")
    Submit(x, y, element_id, "button_name")

logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "[%(asctime)s] %(levelname)s - %(message)s"
  
security:
  require_api_key: false  # Set true for production
  allowed_origins:
    - "*"  # Configure CORS properly for production
  max_content_length: 16777216  # 16MB max request size
  
rate_limiting:
  enabled: false  # Enable for production
  requests_per_minute: 60
